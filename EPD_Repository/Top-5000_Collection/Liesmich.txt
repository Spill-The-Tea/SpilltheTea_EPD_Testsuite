In unserem Computerschach-Zeitalter der riesigen, teils 15- bis 25-zügigen Eröffnungsbibliotheken, vor allem aber der mittlerweile für Menschen kaum mehr nachvollziehbaren, extremen taktischen Schlagkraft aller Programme im Mittelspiel, welche die Unterschiede zwischen den Top-Engines in Matches und Turnieren quasi verwischt, kommt (neben dem positionellen Spielverständnis) v.a. einer Komponente der Performance eine ständig größere Bedeutung zu: dem Endspiel.
Ausgehend von der Diskrepanz zwischen dieser Wichtigkeit der letzten Partie-Phase im modernen «Engine-Betrieb» einerseits und dem Mangel an geeignetem modernem Test-Material anderseits - der früher zuweilen verwendete Stellungstest "PET" (http://www.jakob.at/steffen/hossa/testsuites/pet.html) ist inzwischen keine Herausforderung mehr für Engines - hatte ich mich in den vergangenen Monaten daran gemacht, eine umfangreiche Aufgaben-Suite zusammenzustellen, welche als erster Indikator der Endspielfähigkeiten eines (auch neuen) Schachprogramms fungieren sollte.
Diese Sammlung stelle ich hiermit - unter dem Namen «Eigenmann_Endspiel_Test» E-E-T - der (Computerschach-)Allgemeinheit zur Vefügung.

Der E-E-T

...setzt sich aus exakt hundert, in den einschlägigen Datenbanken sowie in verschiedenster Literatur aus den vier Bereichen «Computerschach», «Fernschach», «Historische Turniere» und «Studien» recherchierten Endspiel-Positionen zusammen, welche einer Engine je 60 Sekunden lang zur Berechnung unterbreitet werden sollen, wobei schließlich die Anzahl richtiger Lösungen entscheidet.

Der E-E-T als einheitlich-kompakte Suite ist folgendermaßen charakterisiert:
1. Die Material-Verteilung des E-E-T orientiert sich einigermaßen an der Häufigkeit, wie sie sich zeigt in großen Partien-Sammlungen wie z.B. der bekannten «Mega-Database» oder v.a. der «COMP2006», womit die Affinität der Suite zum «realen Schachleben» angestrebt wurde. (Turmendspiele z.B. nehmen also besonders großen Raum ein). Über detaillierte Angaben bezgl. prozentuale Endspiel-Häufigkeit siehe u.a. hier: (http://f23.parsimony.net/forum50826/messages/77104.htm)

2. Der E-E-T enthält bewusst zahlreiche Positionen aus dem jüngeren und jüngsten internationalen Engine-Engine-Testbetrieb, um schachlich eine weitgehende Nähe dieses Computer-Schach-Tests zu seinem Gegenstand zu gewährleisten. Darüber hinaus räumt der E-E-T dem eher taktischen Element im Endspiel zwangsläufig eine gewisse Priorität ein, da es (vorläufig noch) sinnlos ist, Computerprogramme im Hinblick auf strategische Endspiele zu befragen. Insgesamt werden aber doch im E-E-T jene Engines eher reüssieren, die sowohl gut rechnen können als auch viel wissen.

3. Ein großer Teil der im E-E-T-Aufgaben sind sog. Studien. Diese Kompositionen präsentieren, wo sie auf technisch hohem Niveau daherkommen, die «Idee», den thematischen Kern eines Endspieles oft in besonders «reiner», unverschnörkelter Form, womit sie sehr geeignet sind für CS-Tests. Dabei wurde allerdings auf größtmögliche Realitätsnähe geachtet; bis auf wenige Ausnahmen hätten die verwendeten Studien problemlos auch in tatsächlich gespielten Computer- oder Menschen-Partien entstanden sein können.

4. In schachthematischer Hinsicht deckt der E-E-T ein breites Spektrum ab (ohne natürlich vollständig sein zu wollen): Von der «Ablenkung» bis zum «Zugzwang», vom «Abzug» über den «Entfernten Freibauern» und die «Festung» bis hin zur "Pattfalle" und zum «Zwischenzug» sind zahlreiche Endspiel-relevanten Themata integriert worden. Als CS-Suite geht der Test vereinzelt auch spezifisch Computerschachlichem wie etwa «Nullmove-» oder «Horizont»-Effekten nach. Mit ein paar wenigen Beispielen ist auch der Partie-Bereich «Mittelspiel-Endspiel-Übergang» vertreten; diesem (zumal im Engine-Schach) ebenfalls sehr wichtigen Sektor will sich der Autor aber in einem späteren Stellungstest spezifisch widmen.

5. Der (vorläufige, weil grundsätzlich Hardware-abhängige) Schwierigkeitsgrad des E-E-T ist übers Ganze betrachtet als «mittelschwer» einzustufen. Um für ein möglichst breites Feld an Schachprogrammen praktikabel zu sein, beinhaltet die Suite ebenso eine Reihe von ziemlich schwierigen wie ziemlich leichen Aufgaben. Keine Rolle spielten bei der Auswahl hingegen ästhetische oder gar historische Gesichtspunkte - wiewohl unter diesen 100 Momentaufnahmen selbstverständlich viele herrlichste Zeugnisse schachkünstlerischen Genies der letzten 200 Jahre zu entdecken sind. Dem «eindeutigen Testcharakter» einer Stellung wurde aber in jedem Falle oberste Priorität eingeräumt.

6. Um auch hinsichtlich der zu verwendenden Bedenkzeit im E-E-T den Bezug zur «Realität» herzustellen, wurden 60 Sekunden pro Stellung veranschlagt. Eine Minute pro Zug mag einem «normalen Vereinsspieler» (=Computerschach-Unkundigen?) nicht sehr lang vorkommen. Tatsächlich aber trifft man soviel durchschnittliche Endspiel-BZ im internationalen Programm-Testbetrieb kaum mehr an; der wahrscheinlich weitaus größte Teil aller CS-Matches und -Turniere wickelt sich in den Blitz- und Rapid-Zeitzonen von 1 bis 25 Minuten pro Partie/Engine ab. Insofern sind also diese 60 Sekunden ein Kompromiss zwischen der Turnierschach- (=2Stunden/Engine) und der Blitzschach- (=5Minuten/Engine) Praxis.

7. In der Computerschach-Szene sind spezielle Endspiel-Datenbanken gebräuchlich - siehe zur Information auch hier: [http://de.wikipedia.org/wiki/Endspiel-Datenbank_%28Schach%29] Auch für den E-E-T sind diese «3-6-Steiner» nicht ganz irrelevant bzw. hilfreich, aber der «Nalimov-Effekt» dürfte sich (sowohl positiv wie negativ) in Grenzen halten. Wie man an untenstehenden Beispiel-Ergebnissen sieht, finden sich TB-unterstützende Programme sowohl im vordersten als auch im hintersten Viertel des Ranking-Feldes.

8. Die Zug-Kommentare zu den einzelnen 100 E-E-T-Aufgaben übernehmen in der Zeichengebung den internationalen «Informator»-Standard und wurden in monatelanger analytischer Arbeit auch unter Einsatz adäquater Software erstellt. Gleichwohl beschränken sie sich aufs Allerwesentlichste - was gleichbedeutend sei mit der Einladung an die Anwenderschaft, sich auch selbst in die Stellungen zu vertiefen und nicht bloß die Maschine all die Arbeit erledigen zu lassen...;-) Der Download beinhaltet neben den (alphabetisch nach Material sortierten) Stellungen&Analysen (PGN-Format) auch ein EPD-File für den Import in alle gängigen Schach-GUIs. Für Anregungen und Kritik aus der Anwenderschaft, sei es zu schachlichen oder konzeptionellen Elementen dieser Suite, bin ich jederzeit dankbar!

9. Der E-E-T will in Sachen «Endspielfähigkeit eines Schachprogrammes» mitnichten als alleinseligmachende Wahrheit daherkommen. Aber ich denke, dass er sein oberstes Ziel erfüllen wird, ein schneller Indikator bei (neuen) Engines bezüglich des so wichtigen dritten Partie-Abschnittes zu sein.

Rothenburg/Schweiz, Dezember 2006
Walter Eigenmann
_______________________________________

U P D A T E (18.Febr. 2007)

Gegenüber der Urfassung wurden drei Aufgaben, welche entweder Nebenlösungen (16&70) enthielten oder sich als unlösbar für Computer erwiesen, ersetzt durch die Aufgaben 98-100.

Rothenburg/Schweiz, Februar 2007
Walter Eigenmann
_______________________________________


Der E-E-T in der Praxis

Die folgenden E-E-T-Resultate wurden bei 60 Sekunden/Engine mit einem Athlon64/3000+ (128MB Hash) sowie den 3-5-Nalimov-TBs unter der «Fritz10»-Oberfläche erspielt. Die Auswahl der Programme (aus dem oberen, mittleren und unteren Stärke-Bereich) soll v.a. das extreme Endspiel-Leistungsgefälle innerhalb des ganzen Engine-Spektrums dokumentieren:

    Programm               Lösungen   Zeitverbrauch

01. Shredder 10             68/100      00:45:17
02. Rybka 2.2               64/100      00:50:48
03. Fritz 10                63/100      00:49:47
04. Rybka WinFinder 2.2     61/100      00:48:54
05. Deep Frenzee 3.0(UCI)   61/100      00:54:04
06. Rybka 1.01 B13d         59/100      00:56:31
07. Chess Tiger 2007        54/100      00:58:55
08. Spike 1.2 Turin         53/100      00:59:42
09. Ktulu 8                 50/100      01:02:55
10. Pharaon 3.5.1           50/100      01:03:32
11. Yace 0.99.87            50/100      01:04:44
12. Naum 2.0                50/100      01:06:08
13. Loop 10.32f             49/100      01:06:25
14. Hiarcs 10               49/100      01:08:33
15. Ruffian 2.1.0           48/100      01:05:41
16. Toga II 1.2.1a          48/100      01:06:05
17. Crafty 20.14 (CB)       47/100      01:05:26
18. Glaurung 1.2.1          46/100      01:09:19
19. Chess Tiger 15.0        46/100      01:10:23
20. Alaric 0702b            45/100      01:06:54
21. Gandalf 6.0             44/100      01:06:00
22. Patzer 3.8              42/100      01:06:50
23. Anaconda 2.0.1          40/100      01:16:26
24. Junior 10               39/100      01:12:44
25. Aristarch 4.50          39/100      01:13:41
26. Nimzo 8                 38/100      01:13:14
27. Pepito 1.59             38/100      01:15:16
28. Movei 0.08.402          35/100      01:16:22
29. Amyan 1.597             35/100      01:16:58
30. LGoliath Evolution      34/100      01:14:21
31. Gaia 3.5                33/100      01:17:55
32. Tao 5.6                 31/100      01:19:42
33. Sjeng 12.13             28/100      01:18:33
34. AnMon 5.60              28/100      01:22:54
35. SOS 5                   27/100      01:21:49
36. GreKo 5.0               24/100      01:25:15
37. Ufim 8.02               23/100      01:24:18
38. Queen 3.09              19/100      01:26:43
39. Abrok 5.0               19/100      01:28:31
40. Homer 1.1 b3            14/100      01:32:10

________________________________________

